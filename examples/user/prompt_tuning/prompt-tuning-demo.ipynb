{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1ca29f",
   "metadata": {},
   "source": [
    "# Prompt tuning example of 'google/flan-t5-xl' model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae303c2",
   "metadata": {},
   "source": [
    "## Library imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4aeb91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import time\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0cfe80",
   "metadata": {},
   "source": [
    "## Dynamicly import 'datasets' library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "02d6ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from datasets import load_dataset\n",
    "except ImportError:\n",
    "    print(\"Install datasets: it is a pre-requisite to run this example\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc13ed78",
   "metadata": {},
   "source": [
    "## Dynamicly import of 'pandas' library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "28906450",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    print(\"Install pandas: it is a pre-requisite to run this example\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228a2cb",
   "metadata": {},
   "source": [
    "## Import of GenAI libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f33cef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai.credentials import Credentials # To load API key\n",
    "from genai.model import Model # To create a model\n",
    "from genai.schemas.generate_params import GenerateParams # To create the model params\n",
    "from genai.schemas.tunes_params import CreateTuneHyperParams, TunesListParams # To create params for tuning\n",
    "from genai.services import FileManager # To upload data files for tune to workbench\n",
    "from genai.services.tune_manager import TuneManager # This is the class to invoke tune methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc3f33",
   "metadata": {},
   "source": [
    "## Load API credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "54fd51da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dotenv is a zero-dependency module that loads environment variables from a .env file into process.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9b6de",
   "metadata": {},
   "source": [
    "## Declare filepaths and other variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1096fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "data_root = os.path.join(current_path,\"data\")\n",
    "training_file = os.path.join(data_root,\"fpb_train.jsonl\")\n",
    "validation_file = os.path.join(data_root,\"fpb_validation.jsonl\")\n",
    "\n",
    "num_training_samples = 100\n",
    "num_validation_samples = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1dbef0",
   "metadata": {},
   "source": [
    "# Declare a function to create a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9fda3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    Path(data_root).mkdir(parents=True, exist_ok=True)\n",
    "#     if training_file.exists() and validation_file.exists():\n",
    "    if path.exists(training_file) and path.exists(validation_file):\n",
    "        return\n",
    "    data = load_dataset(\n",
    "        \"financial_phrasebank\",\n",
    "        \"sentences_allagree\",\n",
    "    )\n",
    "    df = pd.DataFrame(data[\"train\"]).sample(n=num_training_samples + num_validation_samples)\n",
    "    df.rename(columns={\"sentence\": \"input\", \"label\": \"output\"}, inplace=True)\n",
    "    df[\"output\"] = df[\"output\"].astype(str)\n",
    "    train_jsonl = df.iloc[:num_training_samples].to_json(orient=\"records\", lines=True, force_ascii=True)\n",
    "    validation_jsonl = df.iloc[num_training_samples:].to_json(orient=\"records\", lines=True, force_ascii=True)\n",
    "    with open(training_file, \"w\") as fout:\n",
    "        fout.write(train_jsonl)\n",
    "    with open(validation_file, \"w\") as fout:\n",
    "        fout.write(validation_jsonl)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b7ae382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# create_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a4440",
   "metadata": {},
   "source": [
    "# Declare a function to upload the tuning files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "caa6c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files(creds, update=True):\n",
    "    fileinfos = FileManager.list_files(credentials=creds).results\n",
    "    filenames_to_id = {f.file_name: f.id for f in fileinfos}\n",
    "    for filepath in [training_file, validation_file]:\n",
    "        filename = Path(filepath).name\n",
    "        if update and filename in filenames_to_id:\n",
    "            print(f\"File already present: Overwriting {filename}\")\n",
    "            FileManager.delete_file(credentials=creds, file_id=filenames_to_id[filename])\n",
    "            FileManager.upload_file(credentials=creds, file_path=str(filepath), purpose=\"tune\")\n",
    "        if filename not in filenames_to_id:\n",
    "            print(f\"File not present: Uploading {filename}\")\n",
    "            FileManager.upload_file(credentials=creds, file_path=str(filepath), purpose=\"tune\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5719b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already present: Overwriting fpb_train.jsonl\n",
      "File already present: Overwriting fpb_validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "# creds = get_creds()\n",
    "# create_dataset()\n",
    "# upload_files(creds, update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c93f67",
   "metadata": {},
   "source": [
    "# Declare a function to get all training and validation files id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56d6c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_ids(creds):\n",
    "    fileinfos = FileManager.list_files(credentials=creds).results\n",
    "    training_file_ids = [f.id for f in fileinfos if f.file_name == Path(training_file).name]\n",
    "    validation_file_ids = [f.id for f in fileinfos if f.file_name == Path(validation_file).name]\n",
    "    return training_file_ids, validation_file_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47e4c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['9d14c064-f76a-4522-a17c-eb1fb8a85fd8'],\n",
       " ['47500724-e9f6-4190-a339-ecee34c62b50'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "# creds = get_creds()\n",
    "# get_file_ids(creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d164fc7",
   "metadata": {},
   "source": [
    "# Declare a function to get your credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "acd06eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_creds():\n",
    "    api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "    endpoint = os.getenv(\"GENAI_API\", None)\n",
    "    creds = Credentials(api_key=api_key, api_endpoint=endpoint)\n",
    "    return creds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f07be22",
   "metadata": {},
   "source": [
    "# MAIN PROGRAM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5adfaf0",
   "metadata": {},
   "source": [
    "## Create tuning dataset and upload it to server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99f18be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already present: Overwriting fpb_train.jsonl\n",
      "File already present: Overwriting fpb_validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "creds = get_creds()\n",
    "create_dataset()\n",
    "upload_files(creds, update=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f70ef7",
   "metadata": {},
   "source": [
    "## Create an instance of a model, create tune parameters, and get the ids of training and validation files uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1ebba60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\"google/flan-t5-xl\", params=None, credentials=creds)\n",
    "# Task: classification\n",
    "hyperparams = CreateTuneHyperParams(num_epochs=2, verbalizer='classify { \"0\", \"1\", \"2\" } Input: {{input}} Output:')\n",
    "training_file_ids, validation_file_ids = get_file_ids(creds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9936f",
   "metadata": {},
   "source": [
    "## Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e98a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the tunning process and assign it to an object to check the status\n",
    "tuned_model = model.tune(\n",
    "    name=\"classification-mpt-tune-api\",\n",
    "    method=\"mpt\",\n",
    "    task=\"classification\",\n",
    "    hyperparameters=hyperparams,\n",
    "    training_file_ids=training_file_ids,\n",
    "    validation_file_ids=validation_file_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f4c7a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING\n",
      "RUNNING\n",
      "RUNNING\n",
      "RUNNING\n",
      "RUNNING\n",
      "RUNNING\n",
      "RUNNING\n",
      "RUNNING\n"
     ]
    }
   ],
   "source": [
    "status = tuned_model.status()\n",
    "while status not in [\"FAILED\", \"HALTED\", \"COMPLETED\"]:\n",
    "    print(status)\n",
    "    time.sleep(20)\n",
    "    status = tuned_model.status()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f1effbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED\n"
     ]
    }
   ],
   "source": [
    "print(tuned_model.status()) # Run to check final status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01402f",
   "metadata": {},
   "source": [
    "\n",
    "## Test the tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "06480f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer =  1\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hi, how are you? I'm doing well\"\n",
    "genparams = GenerateParams(\n",
    "    decoding_method=\"greedy\",\n",
    "    max_new_tokens=50,\n",
    "    min_new_tokens=1,\n",
    ")\n",
    "\n",
    "print(\"Answer = \", tuned_model.generate([prompt])[0].generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "07427d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1-2\n",
      "\t 2-1\n",
      "\t 3-0\n",
      "\t 4-0\n",
      "\t 5-1\n",
      "\t 6-1\n",
      "\t 7-1\n",
      "\t 8-1\n",
      "\t 9-2\n",
      "\t 10-2\n"
     ]
    }
   ],
   "source": [
    "greeting = \"Hello! How are you?\"\n",
    "lots_of_greetings = [greeting] * 10\n",
    "num_of_greeting = 0\n",
    "for result in tuned_model.generate(lots_of_greetings):\n",
    "    num_of_greeting += 1\n",
    "    print(f\"\\t {num_of_greeting}-{result.generated_text}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f849f2",
   "metadata": {},
   "source": [
    "## Listing tunes and getting tune metadata with TuneManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3508ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "List of tunes: \n",
      "\n",
      "\n",
      "id='flan-t5-xl-mpt-kGGKGEyS-2023-07-13-17-44-07' name='classification-mpt-tune-api' model_id='google/flan-t5-xl' model_name='flan-t5-xl (3B)' method_id='mpt' method_name='Multitask Prompt Tuning' status='COMPLETED' task_id='classification' task_name='Classification' parameters=TuneParameters(accumulate_steps=16, batch_size=16, learning_rate=0.3, max_input_tokens=256, max_output_tokens=128, num_epochs=2, num_virtual_tokens=100, verbalizer='classify { \"0\", \"1\", \"2\" } Input: {{input}} Output:') created_at=datetime.datetime(2023, 7, 13, 17, 44, 7, tzinfo=datetime.timezone.utc) preferred=True datapoints=None validation_files=None training_files=None evaluation_files=None status_message=None started_at=datetime.datetime(2023, 7, 13, 17, 44, 8, tzinfo=datetime.timezone.utc) finished_at='2023-07-13T17:46:40.000Z' \n",
      "\n",
      "id='flan-t5-xl-mpt-le7Yfp0u-2023-07-13-02-36-57' name='classification-mpt-tune-api' model_id='google/flan-t5-xl' model_name='flan-t5-xl (3B)' method_id='mpt' method_name='Multitask Prompt Tuning' status='COMPLETED' task_id='classification' task_name='Classification' parameters=TuneParameters(accumulate_steps=16, batch_size=16, learning_rate=0.3, max_input_tokens=256, max_output_tokens=128, num_epochs=2, num_virtual_tokens=100, verbalizer='classify { \"0\", \"1\", \"2\" } Input: {{input}} Output:') created_at=datetime.datetime(2023, 7, 13, 2, 36, 58, tzinfo=datetime.timezone.utc) preferred=True datapoints=None validation_files=None training_files=None evaluation_files=None status_message=None started_at=datetime.datetime(2023, 7, 13, 2, 36, 58, tzinfo=datetime.timezone.utc) finished_at='2023-07-13T02:39:40.000Z' \n",
      "\n",
      "id='flan-t5-xl-mpt-9Bij7V4D-2023-07-13-02-10-38' name='classification-mpt-tune-api' model_id='google/flan-t5-xl' model_name='flan-t5-xl (3B)' method_id='mpt' method_name='Multitask Prompt Tuning' status='COMPLETED' task_id='classification' task_name='Classification' parameters=TuneParameters(accumulate_steps=16, batch_size=16, learning_rate=0.3, max_input_tokens=256, max_output_tokens=128, num_epochs=2, num_virtual_tokens=100, verbalizer='classify { \"0\", \"1\", \"2\" } Input: {{input}} Output:') created_at=datetime.datetime(2023, 7, 13, 2, 10, 38, tzinfo=datetime.timezone.utc) preferred=True datapoints=None validation_files=None training_files=None evaluation_files=None status_message=None started_at=datetime.datetime(2023, 7, 13, 2, 10, 39, tzinfo=datetime.timezone.utc) finished_at='2023-07-13T02:13:30.000Z' \n",
      "\n",
      "id='flan-t5-xl-mpt-K3NF1JEP-2023-07-13-01-22-43' name='classification-mpt-tune-api' model_id='google/flan-t5-xl' model_name='flan-t5-xl (3B)' method_id='mpt' method_name='Multitask Prompt Tuning' status='COMPLETED' task_id='classification' task_name='Classification' parameters=TuneParameters(accumulate_steps=16, batch_size=16, learning_rate=0.3, max_input_tokens=256, max_output_tokens=128, num_epochs=2, num_virtual_tokens=100, verbalizer='classify { \"0\", \"1\", \"2\" } Input: {{input}} Output:') created_at=datetime.datetime(2023, 7, 13, 1, 22, 44, tzinfo=datetime.timezone.utc) preferred=True datapoints=None validation_files=None training_files=None evaluation_files=None status_message=None started_at=datetime.datetime(2023, 7, 13, 1, 22, 45, tzinfo=datetime.timezone.utc) finished_at='2023-07-13T01:26:00.000Z' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_params = TunesListParams(limit=5, offset=0)\n",
    "\n",
    "tune_list = TuneManager.list_tunes(credentials=creds, params=list_params)\n",
    "print(\"\\n\\nList of tunes: \\n\\n\")\n",
    "for tune in tune_list.results:\n",
    "    print(tune, \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e069c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "~~~~~ Metadata for a single tune with TuneManager ~~~~: \n",
      "\n",
      " id='flan-t5-xl-mpt-kGGKGEyS-2023-07-13-17-44-07' name='classification-mpt-tune-api' model_id='google/flan-t5-xl' model_name='flan-t5-xl (3B)' method_id='mpt' method_name='Multitask Prompt Tuning' status='COMPLETED' task_id='classification' task_name='Classification' parameters=TuneParameters(accumulate_steps=16, batch_size=16, learning_rate=0.3, max_input_tokens=256, max_output_tokens=128, num_epochs=2, num_virtual_tokens=100, verbalizer='classify { \"0\", \"1\", \"2\" } Input: {{input}} Output:') created_at=datetime.datetime(2023, 7, 13, 17, 44, 7, tzinfo=datetime.timezone.utc) preferred=True datapoints={'loss': [{'data': {'epoch': 0, 'value': 0.8125, 'timestamp': '2023-07-13T17:46:26.409898'}, 'timestamp': '2023-07-13T17:46:26.409Z'}, {'data': {'epoch': 1, 'value': 0.67578125, 'timestamp': '2023-07-13T17:46:31.066027'}, 'timestamp': '2023-07-13T17:46:31.066Z'}]} validation_files=[{'id': '8c181aad-2058-4d6f-8e7d-f4ecbdbbe1a4', 'file_name': 'fpb_validation.jsonl', 'created_at': '2023-07-13T17:41:23.000Z'}] training_files=[{'id': '77500040-a606-4764-861f-08355e076dbe', 'file_name': 'fpb_train.jsonl', 'created_at': '2023-07-13T17:41:22.000Z'}] evaluation_files=[] status_message=None started_at=datetime.datetime(2023, 7, 13, 17, 44, 8, tzinfo=datetime.timezone.utc) finished_at='2023-07-13T17:46:40.000Z'\n"
     ]
    }
   ],
   "source": [
    "tune_get_result = TuneManager.get_tune(credentials=creds, tune_id=tuned_model.model)\n",
    "print(\n",
    "    \"\\n\\n~~~~~ Metadata for a single tune with TuneManager ~~~~: \\n\\n\",\n",
    "    tune_get_result,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b857b",
   "metadata": {},
   "source": [
    "## Deleting a tuned model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de06e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = \"y\"\n",
    "if to_delete == \"y\":\n",
    "    tuned_model.delete()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba81439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
